{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process:\n",
    "\n",
    "Screening folder data, generate report of source and output data\n",
    "\n",
    "Documentation template:\n",
    "\n",
    "[PyData](https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, datetime\n",
    "\n",
    "class BaseData():\n",
    "    \"\"\"Base class to store the information of the data objects\"\"\"\n",
    "    def __init__(self, file_name, data_name=None,\n",
    "                 url=None, doi=None,\n",
    "                 meta=None, license=None, comments=None,\n",
    "                 tags=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        file_name : str\n",
    "            File name\n",
    "        data_name : str, optional\n",
    "            Name of the dataset\n",
    "        url : str, optional\n",
    "            Source URL of the dataset if available\n",
    "        doi : str, optional\n",
    "            DOI of the dataset if available\n",
    "        meta : str\n",
    "            meta data of the dataset\n",
    "        license : str, optional\n",
    "            License of the dataset\n",
    "        comments : str, optional\n",
    "            Comments of the dataset\n",
    "        tags : list, optional\n",
    "            Tags of the dataset\n",
    "        \"\"\"\n",
    "        # --- directory parser ---\n",
    "        # TODO\n",
    "        self.file_name = file_name\n",
    "        self.directory = None\n",
    "\n",
    "        # --- data description ---\n",
    "        self.data_name = data_name\n",
    "        self.url = url\n",
    "        self.doi = doi\n",
    "        self.meta = meta\n",
    "        self.license = license\n",
    "        self.comments = comments  # TODO: better way to store comments?\n",
    "        self.tags = tags  # [Energy, Economy, Medicine, Sociology, ], Ungrouped, etc.\n",
    "\n",
    "        # --- data attributes ---\n",
    "        self.size = None\n",
    "        self.type = None  # ['csv', 'txt', etc.]\n",
    "        self.is_split = False  # True if the file is split into multiple files\n",
    "\n",
    "        # --- data timestamp ---\n",
    "        self.created_time = None\n",
    "        self.archived_time = datetime.datetime.now()\n",
    "        self.accessed_time = None\n",
    "        self.modified_time = None\n",
    "\n",
    "    def save(self, filename):\n",
    "        \"\"\"Save data to file\"\"\"\n",
    "        # if the file size is larger than XX MB\n",
    "        # seperate it into multiple files\n",
    "        # TODO: find popular file size limit\n",
    "        pass\n",
    "\n",
    "\n",
    "class CSVData(BaseData):\n",
    "    \"\"\"Class for CSV data\"\"\"\n",
    "    # NOTE: should we consider Dask rather than Pandas?\n",
    "    pass\n",
    "\n",
    "\n",
    "class MapData(BaseData):\n",
    "    \"\"\"Class for map data\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "# TODO: document the stored data\n",
    "\n",
    "\n",
    "# TODO: ArcGIS API?\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
